{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts by Pavel Gladkevich\n",
    "This project was completed as part of the Data Analyst series of [Dataquest](https://www.dataquest.io/directory/) on 05/31/19 \n",
    "<br/><br/>\n",
    "**Goal:** To analyze posts from the [Hacker News Site](https://news.ycombinator.com/), a popular technology related forum where users post stories that are voted upon and have comment sections. Users of this site can submit ask, show, job, and other posts. In our analyisis we will first look at whether ask or show posts get more comments, and what at what time does the more popular category's post receive the most comments. \n",
    "<br/><br/>\n",
    "Thus, we will do a per hour analysis of posts and comments to identify a post that receives the greatest response rate. The data was obtained from the kaggle repository: [Hacker News Dataset](https://www.kaggle.com/hacker-news/hacker-news-posts/downloads/hacker-news-posts.zip/1). It contains a years worth of data collected from September 2015 to September 2016. We will reduce the dataset from roughly 300,000 to only contain the approximatley 80,000 posts that have comments. The time data was taken in US Eastern time so it is either EST/EDT and will be converted to my local timezone of PST/PDT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the original dataset 293120\n",
      "Dataset containing only posts with comments 80402\n"
     ]
    }
   ],
   "source": [
    "# Load the downloaded csv file of Hacker News Data from file path\n",
    "open_file = open(\"/Users/pgladkevich/Desktop/coding/projects/datasets/HN_posts_year_to_Sep_26_2016.csv\")\n",
    "\n",
    "# Import reader which will iterate over lines in the given csvfile.\n",
    "from csv import reader\n",
    "\n",
    "hacker_news = reader(open_file)\n",
    "\n",
    "# Turn data set file into list of lists format\n",
    "h_list = list(hacker_news)\n",
    "print(\"The length of the original dataset\",len(h_list))\n",
    "\n",
    "# Delete all entries that do not have at least one comment\n",
    "hn = []\n",
    "for row in h_list:\n",
    "    num_comments = row[4]\n",
    "    if num_comments != '0':\n",
    "        hn.append(row)\n",
    "print(\"Dataset containing only posts with comments\",len(hn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12578975', 'Saving the Hassle of Shopping', 'https://blog.menswr.com/2016/09/07/whats-new-with-your-style-feed/', '1', '1', 'bdoux', '9/26/2016 3:13']\n",
      "\n",
      "\n",
      "['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']\n",
      "\n",
      "\n",
      "['12578822', 'Amazons Algorithms Dont Find You the Best Deals', 'https://www.technologyreview.com/s/602442/amazons-algorithms-dont-find-you-the-best-deals/', '1', '1', 'yarapavan', '9/26/2016 2:26']\n",
      "\n",
      "\n",
      "['12578694', 'Emergency dose of epinephrine that does not cost an arm and a leg', 'http://m.imgur.com/gallery/th6Ua', '2', '1', 'dredmorbius', '9/26/2016 1:54']\n",
      "\n",
      "\n",
      "Number of rows is  80402\n",
      "Number of columns is  7\n"
     ]
    }
   ],
   "source": [
    "# Function that prints the desired number of rows from an interval in the dataset and optionally the num rows/columns\n",
    "def explore_data(dataset, start=1,end=5,r_and_c=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n')\n",
    "    \n",
    "    if r_and_c:\n",
    "        #the number of rows in the dataset is the amount of entries unless a header is included then -1\n",
    "        print('Number of rows is ', len(dataset))\n",
    "        #the number of columns is the number of values in a single row since list of lists format\n",
    "        print('Number of columns is ', len(dataset[0]))\n",
    "\n",
    "explore_data(hn,0,r_and_c=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove header\n",
    "headers = hn[0]\n",
    "\n",
    "# Dataset without header\n",
    "hn = hn[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Ask and Show Posts\n",
    "We have a dataset containing only posts with comments so now we can proceed to sort the posts into categories for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts in  ask_posts  is  6911\n",
      "Number of posts in  show_posts  is  5059\n",
      "Number of posts in  other_posts  is  68431\n"
     ]
    }
   ],
   "source": [
    "# Create lists to bin the different categories of posts\n",
    "ask_posts, show_posts, other_posts = ([] for i in range(3))\n",
    "posts = [ask_posts, show_posts, other_posts]\n",
    "\n",
    "# Loop through the hn data and sort each post based off of its title\n",
    "for row in hn:\n",
    "    # Set the post's title in lowercase to a variable\n",
    "    title = row[1].lower()\n",
    "    \n",
    "    # Append post data to list if ask post\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    # Append post data to list if show post\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    # Append to other if neither\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "# Check numbers of posts in each category\n",
    "posts_s = [\"ask_posts\", \"show_posts\", \"other_posts\"]\n",
    "for i in range(3):\n",
    "    name = posts_s[i]\n",
    "    print(\"Number of posts in \", name,\" is \", len(posts[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Avg # of Comments\n",
    "Now that we have our categories we are interested in looking at we can compute the average number of posts in each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ask and show posts are 13.74 and 9.81 respectively.\n"
     ]
    }
   ],
   "source": [
    "# Create variables to store comment numbers\n",
    "total_ask_comments, total_show_comments = 0,0\n",
    "\n",
    "# Iterate over ask posts to count comments on each\n",
    "for row in ask_posts:\n",
    "    # set number of comments to integer variable\n",
    "    num_comments = int(row[4])\n",
    "    #add to total\n",
    "    total_ask_comments += num_comments\n",
    "    \n",
    "# Iterate over show posts to count comments on each\n",
    "for row in show_posts:\n",
    "    # Set number of comments to integer variable\n",
    "    num_comments = int(row[4])\n",
    "    # Add to total\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "# Compute averages for both categories of posts\n",
    "num_ask_posts = len(ask_posts)\n",
    "num_show_posts = len(show_posts)\n",
    "avg_ask_posts = total_ask_comments/num_ask_posts\n",
    "avg_show_posts = total_show_comments/num_show_posts\n",
    "\n",
    "print(\"Average ask and show posts are\", round(avg_ask_posts, 2),\"and\", round(avg_show_posts,2), \"respectively.\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the mean number of comments on ask posts is significantly higher than the number of comments on show posts. This result is intuitive since an ask post will inherently induce responses since it is asking a question. While the amount of people viewing the two categories of posts may or may not be different, I believe it is likely that in cases of equal viewership the asks posts will inherently have a greater response rate. \n",
    "\n",
    "## Average Ask Posts and Comments by Hour\n",
    "Since ask posts are more likely to receive comments, it will be the focus of the rest of work since our goal is to identify the type and time of the post that has the highest response rate. To this end we will use the datetime library of python to sort the posts by frequency per hour in each of the two categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['02', 13.198237885462555, 2], ['01', 9.367713004484305, 2], ['22', 11.749128919860627, 2], ['21', 11.056511056511056, 2], ['19', 9.414285714285715, 2], ['17', 13.73019801980198, 2], ['15', 39.66809421841542, 2], ['14', 13.153439153439153, 2], ['13', 22.2239263803681, 2], ['11', 11.143426294820717, 2], ['10', 13.757990867579908, 2], ['09', 8.392045454545455, 2], ['07', 10.095541401273886, 2], ['03', 10.160377358490566, 2], ['16', 10.76144578313253, 2], ['08', 12.43157894736842, 2], ['00', 9.857142857142858, 2], ['23', 8.322463768115941, 2], ['20', 11.38265306122449, 2], ['18', 10.789823008849558, 2], ['12', 15.452554744525548, 2], ['04', 12.688172043010752, 2], ['06', 9.017045454545455, 2], ['05', 11.139393939393939, 2]]\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# Create a list of lists that will store the time and number of comments for each ask post\n",
    "result_list =  []\n",
    "for row in ask_posts:\n",
    "    # Get the time\n",
    "    created_at = row[6]\n",
    "    # Get the num of comments as an integer\n",
    "    num_comments = int(row[4])\n",
    "    result_list.append([created_at, num_comments])\n",
    "\n",
    "# Create two dictionaries that will be used to create hourly frequency tables\n",
    "counts_by_hour, comments_by_hour = {}, {}\n",
    "\n",
    "# Loop through result_list to populate dictionaries\n",
    "for row in result_list:\n",
    "    # Extract the hour from the date and create datetime object\n",
    "    date = row[0]\n",
    "    num_comments = row[1]\n",
    "    dt_h = dt.datetime.strptime(date, \"%m/%d/%Y %H:%M\")\n",
    "    hour = dt.datetime.strftime(dt_h, \"%H\")\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += num_comments\n",
    "    else: \n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = num_comments  \n",
    "\n",
    "# Create list of lists with hour and average num comments per post in that hour\n",
    "hourly_avg_comments = []\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    total_posts = counts_by_hour[hour]\n",
    "    total_comments = comments_by_hour[hour]\n",
    "    avg_by_hour = total_comments/total_posts\n",
    "    hourly_avg_comments.append([hour,avg_by_hour,2])\n",
    "    \n",
    "print(hourly_avg_comments)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Top 5 times for Ask HN Posts by Comments\n",
    "We now have the per hourly average number of comments for each post, but we have to do some more work to get it into a more readable format so that we can easily scan the best times to post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for 'Ask HN' Comments\n",
      "12:00 | 39.67 comments per hour on average\n",
      "10:00 | 22.22 comments per hour on average\n",
      "09:00 | 15.45 comments per hour on average\n",
      "07:00 | 13.76 comments per hour on average\n",
      "14:00 | 13.73 comments per hour on average\n"
     ]
    }
   ],
   "source": [
    "# Swap columns of list to prepare for sorting\n",
    "swap_h_avg_comments = []\n",
    "for hour in hourly_avg_comments:\n",
    "    swap_h_avg_comments.append([hour[1],hour[0]])\n",
    "\n",
    "# Sorting the swapped list in ascending order\n",
    "sorted_swap = sorted(swap_h_avg_comments, reverse=True)\n",
    "\n",
    "# Print the top 5 hours to post an Ask\n",
    "print(\"Top 5 Hours for 'Ask HN' Comments\")\n",
    "\n",
    "# Iterated through the top 5 of the sorted list\n",
    "for row in sorted_swap[:5]:\n",
    "    # Create datetime object in PST/PDT\n",
    "    hour = int(row[1]) - 3\n",
    "    # Edge case where if 2-3 = -1 it is instead 23 hours\n",
    "    if hour == -1:\n",
    "        hour = 23        \n",
    "    h_dt = dt.datetime.strptime(str(hour),'%H')\n",
    "    \n",
    "    # Convert it to string\n",
    "    hour = dt.datetime.strftime(h_dt, '%H:%M')\n",
    "    avg = row[0]\n",
    "    \n",
    "    #Create the string to be printed\n",
    "    hour_avg = \"{0} | {1:.2f} comments per hour on average\".format(hour, avg)\n",
    "    print(hour_avg)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time in the left column is in 24hour time PST/PDT. This means that 12:00 is 12PM and 23:00 is 11 PM. It appears that the best time to post in order to receive the highest amount of comments is at 12PM PST. This is lunchtime/late afternoon for the US. In general the top three times are clustered at the morning to early afternoon for the US depending on the timezone of either PST/PDT or EST/EDT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We analyzed the data of 80,000 Hacker News posts that contained at least one comment. Our purpose was to identify whether an 'ASK HN' or a 'SHOW HN' post receives more comments, and when is the best time to post the winner of these two. For this dataset the HN ask and show posts contained 13.74 and 9.81 comments on average respectively. Thus, for our goal of achieving the highest likelihood of high comment count we focused on 'ASK HN' posts. When we performed a time analysis of the 'ASK HN' comments it appears that the best time is between the hours of 9 to 12 AM PST/PDT, which is 12 to 3 PM in EST/EDT. Thus, our results indicate that of the posts that have received comments the optimal response rate would be achieved with a 'ASK HN' post at 12:00 PM PST/PDT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
